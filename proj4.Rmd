---
title: "project4"
output:
  html_document: default
---
```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
# install.packages("stringr")
# install.packages("tm")
# install.packages("qdap")
# install.packages('rJava')
# install.packages('plyr')
# install.packages('knitr')
# install.packages('tidyverse')
library(tidyverse)
library(rJava)
library(tm)
library(qdap)
library(stringr)
library(plyr)
library(knitr)
```

##Get files and name the columns.
```{r}
spams <- list.files("C:/Users/neilhwang/Downloads/spam/", full.names = TRUE)
hams <- list.files("C:/Users/neilhwang/Downloads/easy_ham/", full.names = TRUE)
df_names <- c('expression', 'context', 'count', 'classification')
```

##Data Collection

Define several utility functions for use later.
```{r}
# Run experiments on test data 
run_experiment <- function(test_file){
  ham_count = 0
  spam_count = 0
  
  for (i in 1:length(test_file)){
    if (test_file[i] != 'NA'){
      if (spam_likelihood(test_file[i]) == 'spam'){
        spam_count = spam_count + 1
      } else {
        ham_count = ham_count + 1
      }
    }
  }
  print(spam_count)
  print(ham_count)
}

# Uses likelihood to figure out the likely classification
spam_likelihood <- function(file_path){
  content <- readLines(file_path)
  temp <- paste(content, collapse = ' ')
  terms <- strsplit(temp, "\\W+")
  terms_df <- data.frame(terms)
  colnames(terms_df) <- "danuh"
  terms_df$danuh <- tolower(terms_df$danuh)
  total_score <- sum(combined$score[terms_df$danuh == combined$expression])
  if(!is.na(total_score)){
    if (total_score > 0){
      return('spam')
    } else {
      return('ham')  
    }
  } else {
    return('spam')
  }
}

# Put together a master corpus of either spam  or ham based on input
append_tm <- function(path_files){
  temp_content = c()
  i <- 0
  for (cur_file in path_files){
    current_content <- readLines(cur_file)
    temp_content <- c(temp_content, current_content)
    i <- (i+1)
    if (i == 50){
      return(Corpus(VectorSource(temp_content)))
    }
  }
  return (Corpus(VectorSource(temp_content)))
}

spam <- append_tm(spams)
ham <- append_tm(hams)
```

## Data munging.
```{r}
control_tdm <- list(removePunctuation=TRUE, removeNumbers=TRUE, stripWhitespace=TRUE)
spam_df <- data.frame(as.table(TermDocumentMatrix(spam, control = control_tdm)))
ham_df <- data.frame(as.table(TermDocumentMatrix(ham, control = control_tdm)))
spam_df[['category']] <- "spam"
ham_df[['category']] <- "ham"

colnames(spam_df) <- df_names
colnames(ham_df)  <- df_names
spam_df$count[is.na(spam_df$count)] <- '0'
spam_df <- spam_df %>% 
  ddply(.(expression, classification), summarize, count = sum(as.numeric(count)))

ham_df$count[is.na(ham_df$count)] <- '0'
ham_df <- ham_df %>% 
  ddply(.(expression, classification), summarize, count = sum(as.numeric(count)))

combined <- merge(x = ham_df, y = spam_df, by=c("expression", "count", "classification"), all = TRUE)
combined$count[is.na(combined$count)] <- '0'
combined$classification[is.na(combined$classification)] <- 'spam'
combined$count[is.na(combined$count)] <- '0'
combined$classification[is.na(combined$classification)] <- 'ham'
combined[is.na(combined)] <- '0'
combined$score <- as.numeric(combined$count) - as.numeric(combined$count)
```

##Run experiment on test data set.
Based on the results of the ham dataset of 2,501 documents, it correctly classifies all but 3 as ham. However, based on the spam data set, the false negative rate is also quite high, incorrectly classifying 1395 of the 1398 spam messages as ham. 
```{r}
spams_test <- list.files("C:/Users/neilhwang/Downloads/spam_2/", full.names = TRUE)
hams_test <- list.files("C:/Users/neilhwang/Downloads/easy_ham_2/", full.names = TRUE)
ham_count = 0
spam_count = 0

run_experiment(hams_test)
run_experiment(spams_test)
```